{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567d1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "from sktime.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import Measurements as measurements\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from aeon.classification.dictionary_based import BOSSEnsemble\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import Feature_rank_lib as lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e51359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method extract the necessary features from the destination folder\n",
    "def data_reader(loadPath, partitions, flare_label):\n",
    "    cols = ['USFLUX','TOTUSJZ','TOTUSJH','ABSNJZH','SAVNCPP','TOTPOT','TOTBSQ','TOTFZ','MEANPOT','EPSZ','MEANSHR','SHRGT45','MEANGAM','MEANGBT','MEANGBZ','MEANGBH','MEANJZH','TOTFY','MEANJZD','MEANALP','TOTFX','EPSY','EPSX','R_VALUE']\n",
    "    # Read files from the define path\n",
    "    all_files = glob.glob(str(loadPath) + partitions + \"/\" + flare_label + \"/*.csv\")\n",
    "\n",
    "    li = []\n",
    "    for filename in all_files:\n",
    "        # Read the file and extract necessary features\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, sep='\\t')\n",
    "        df.interpolate(method='linear', axis=0, limit_direction='both', inplace = True)\n",
    "#         # Extract label info\n",
    "#         INFO = filename.split('/')[-1]\n",
    "        # Define Label value based on the file name\n",
    "    \n",
    "        if flare_label == 'NF':\n",
    "            LABEL = 'CBN'\n",
    "        else:\n",
    "            LABEL = 'XM'\n",
    "            \n",
    "        col_list = []\n",
    "        for col in cols:\n",
    "            if not df[col].isnull().values.all(axis=0):\n",
    "                col_list.append(df[col])\n",
    "        if len(col_list) == 24:\n",
    "            li.append(col_list + [LABEL])\n",
    "\n",
    "    # Create and return the dataframe build on the extracted features\n",
    "    partition_frame = pd.DataFrame(li, columns= cols + ['LABEL'])\n",
    "    return partition_frame\n",
    "\n",
    "def evaluation(x_test, y_test, y_pred, clf):\n",
    "    scores = confusion_matrix(y_test, y_pred, labels=['CBN', 'XM']).ravel()\n",
    "    tn, fp, fn, tp = scores\n",
    "\n",
    "    results_DF = pd.DataFrame(columns = ['Confusion_Matrix(tn, fp, fn, tp)', 'Accur', 'TSS', 'HSS', 'GSS', 'TPR', 'TNR', 'CBNPr', 'XMPr', 'FAR', 'POFD', 'f1XM', 'f1CBN'], index = [0])\n",
    "\n",
    "    #Confusion Matrix\n",
    "    results_DF['Confusion_Matrix(tn, fp, fn, tp)'] = [scores]\n",
    "    \n",
    "    #Accuracy\n",
    "    scoreTest = clf.score(x_test, y_test)\n",
    "    #print(\"Train Accuracy: \" + str(round(scoreTrain, 4)))\n",
    "    #print(\"Test Accuracy: \" + str(round(scoreTest, 4)))\n",
    "    results_DF['Accur'] = scoreTest\n",
    "\n",
    "    # TSS\n",
    "    tss = measurements.TSS(scores)\n",
    "    results_DF['TSS'] = tss\n",
    "\n",
    "    # HSS2 Definition 2\n",
    "    hss2 = measurements.HSS2(scores)\n",
    "    results_DF['HSS'] = hss2\n",
    "\n",
    "    # GSS\n",
    "    gss = measurements.GSS(scores)\n",
    "    results_DF['GSS'] = gss\n",
    "\n",
    "    # TPR\n",
    "    tpr = measurements.TPR(scores)\n",
    "    results_DF['TPR'] = tpr\n",
    "    \n",
    "    # TNR\n",
    "    tnr = measurements.TNR(scores)\n",
    "    results_DF['TNR'] = tnr\n",
    "\n",
    "    # Precision Negative\n",
    "    negPrecision = measurements.precisionNeg(scores)\n",
    "    results_DF['CBNPr'] = negPrecision\n",
    "    \n",
    "    # Precision Positive\n",
    "    posPrecision = measurements.precisionPos(scores)\n",
    "    results_DF['XMPr'] = posPrecision\n",
    "\n",
    "    # FAR\n",
    "    far = measurements.FAR(scores)\n",
    "    results_DF['FAR'] = far\n",
    "\n",
    "    # POFD\n",
    "    pofd = measurements.POFD(scores)\n",
    "    results_DF['POFD'] = pofd\n",
    "\n",
    "    # F1(XM)\n",
    "    f1XM = measurements.F1Pos(scores)\n",
    "    results_DF['f1XM'] = f1XM\n",
    "\n",
    "    # F1(CBN)\n",
    "    f1CBN = measurements.F1Neg(scores)\n",
    "    results_DF['f1CBN'] = f1CBN\n",
    "\n",
    "    # Return the result measurement dataframe\n",
    "    return results_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475aae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/data/SHARPS/BERKAY/v0.7/new-data-folds/instances_O12L0P24/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ae0cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partition1_FL = data_reader(datapath,'partition1','FL')\n",
    "partition1_NF = data_reader(datapath,'partition1','NF')\n",
    "\n",
    "partition2_FL = data_reader(datapath,'partition2','FL')\n",
    "partition2_NF = data_reader(datapath,'partition2','NF')\n",
    "\n",
    "partition3_FL = data_reader(datapath,'partition3','FL')\n",
    "partition3_NF = data_reader(datapath,'partition3','NF')\n",
    "\n",
    "partition4_FL = data_reader(datapath,'partition4','FL')\n",
    "partition4_NF = data_reader(datapath,'partition4','NF')\n",
    "\n",
    "partition5_FL = data_reader(datapath,'partition5','FL')\n",
    "partition5_NF = data_reader(datapath,'partition5','NF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c3b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition1 = pd.concat([partition1_FL, partition1_NF], ignore_index=True)\n",
    "partition2 = pd.concat([partition2_FL, partition2_NF], ignore_index=True)\n",
    "partition3 = pd.concat([partition3_FL, partition3_NF], ignore_index=True)\n",
    "partition4 = pd.concat([partition4_FL, partition4_NF], ignore_index=True)\n",
    "partition5 = pd.concat([partition5_FL, partition5_NF], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d51079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition1 = np.concatenate((partition1_FL, partition1_NF))\n",
    "# partition2 = np.concatenate((partition2_FL, partition2_NF))\n",
    "# partition3 = np.concatenate((partition3_FL, partition3_NF))\n",
    "# partition4 = np.concatenate((partition4_FL, partition4_NF))\n",
    "# partition5 = np.concatenate((partition5_FL, partition5_NF))\n",
    "\n",
    "# partition1_labels = np.concatenate((partition1_FL_labels, partition1_NF_labels))\n",
    "# partition2_labels = np.concatenate((partition2_FL_labels, partition2_NF_labels))\n",
    "# partition3_labels = np.concatenate((partition3_FL_labels, partition3_NF_labels))\n",
    "# partition4_labels = np.concatenate((partition4_FL_labels, partition4_NF_labels))\n",
    "# partition5_labels = np.concatenate((partition5_FL_labels, partition5_NF_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15074514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "# from sktime.transformations.panel.rocket import Rocket\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2eb7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TEp5 = pd.concat([partition1, partition2, partition3, partition4], ignore_index=True)\n",
    "X_train_TEp4 = pd.concat([partition1, partition2, partition3, partition5], ignore_index=True)\n",
    "X_train_TEp3 = pd.concat([partition1, partition2, partition4, partition5], ignore_index=True)\n",
    "X_train_TEp2 = pd.concat([partition1, partition3, partition4, partition5], ignore_index=True)\n",
    "X_train_TEp1 = pd.concat([partition2, partition3, partition4, partition5], ignore_index=True)\n",
    "\n",
    "y_train_TEp5 = X_train_TEp5['LABEL']\n",
    "X_train_TEp5 = X_train_TEp5.loc[:, X_train_TEp5.columns != 'LABEL']\n",
    "y_train_TEp4 = X_train_TEp4['LABEL']\n",
    "X_train_TEp4 = X_train_TEp4.loc[:, X_train_TEp4.columns != 'LABEL']\n",
    "y_train_TEp3 = X_train_TEp3['LABEL']\n",
    "X_train_TEp3 = X_train_TEp3.loc[:, X_train_TEp3.columns != 'LABEL']\n",
    "y_train_TEp2 = X_train_TEp2['LABEL']\n",
    "X_train_TEp2 = X_train_TEp2.loc[:, X_train_TEp2.columns != 'LABEL']\n",
    "y_train_TEp1 = X_train_TEp1['LABEL']\n",
    "X_train_TEp1 = X_train_TEp1.loc[:, X_train_TEp1.columns != 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c79fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_TEp5 = partition5.loc[:, partition5.columns != 'LABEL']\n",
    "y_test_TEp5 = partition5['LABEL']\n",
    "X_test_TEp4 = partition4.loc[:, partition4.columns != 'LABEL']\n",
    "y_test_TEp4 = partition4['LABEL']\n",
    "X_test_TEp3 = partition3.loc[:, partition3.columns != 'LABEL']\n",
    "y_test_TEp3 = partition3['LABEL']\n",
    "X_test_TEp2 = partition2.loc[:, partition2.columns != 'LABEL']\n",
    "y_test_TEp2 = partition2['LABEL']\n",
    "X_test_TEp1 = partition1.loc[:, partition1.columns != 'LABEL']\n",
    "y_test_TEp1 = partition1['LABEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3743b",
   "metadata": {},
   "source": [
    "# Result for non-optimized class weight Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d830ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing p5')\n",
    "t0=time.time()\n",
    "rocket_TEp5 = RocketClassifier(n_jobs=10)\n",
    "rocket_TEp5.fit(X_train_TEp5, y_train_TEp5)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "t1=time.time()\n",
    "y_pred_TEp5 = rocket_TEp5.predict(X_test_TEp5)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "np.save('./results/Rocket/y_pred_TEp5.npy', y_pred_TEp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee7b8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p4\n",
      "\tPredicting time: 1537.04 s\n"
     ]
    }
   ],
   "source": [
    "print('Testing p4')\n",
    "t0=time.time()\n",
    "rocket_TEp4 = RocketClassifier(n_jobs=10)\n",
    "rocket_TEp4.fit(X_train_TEp4, y_train_TEp4)\n",
    "t1=time.time()\n",
    "y_pred_TEp4 = rocket_TEp4.predict(X_test_TEp4)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "np.save('./results/Rocket/y_pred_TEp4.npy', y_pred_TEp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d4aa4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p3\n",
      "\tTraining time: 18113.63 s\n",
      "\tPredicting time: 1244.69 s\n"
     ]
    }
   ],
   "source": [
    "print('Testing p3')\n",
    "t0=time.time()\n",
    "rocket_TEp3 = RocketClassifier(n_jobs=10)\n",
    "rocket_TEp3.fit(X_train_TEp3, y_train_TEp3)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "t1=time.time()\n",
    "y_pred_TEp3 = rocket_TEp3.predict(X_test_TEp3)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "np.save('./results/Rocket/y_pred_TEp3.npy', y_pred_TEp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77bbc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p2\n",
      "\tTraining time: 17380.49 s\n",
      "\tPredicting time: 2624.53 s\n"
     ]
    }
   ],
   "source": [
    "print('Testing p2')\n",
    "t0=time.time()\n",
    "rocket_TEp2 = RocketClassifier(n_jobs=10)\n",
    "rocket_TEp2.fit(X_train_TEp2, y_train_TEp2)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "t1=time.time()\n",
    "y_pred_TEp2 = rocket_TEp2.predict(X_test_TEp2)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "np.save('./results/Rocket/y_pred_TEp2.npy', y_pred_TEp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb6ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p1\n",
      "\tTraining time: 19717.11 s\n",
      "\tPredicting time: 2185.55 s\n"
     ]
    }
   ],
   "source": [
    "print('Testing p1')\n",
    "t0=time.time()\n",
    "rocket_TEp1 = RocketClassifier(n_jobs=10)\n",
    "rocket_TEp1.fit(X_train_TEp1, y_train_TEp1)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "t1=time.time()\n",
    "y_pred_TEp1 = rocket_TEp1.predict(X_test_TEp1)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "np.save('./results/Rocket/y_pred_TEp1.npy', y_pred_TEp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71575cc",
   "metadata": {},
   "source": [
    "# Optimize class weight within RidgetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c82284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sktime.classification._delegate import _DelegatedClassifier\n",
    "from sktime.pipeline import make_pipeline\n",
    "from sktime.transformations.panel.rocket import (\n",
    "    MiniRocket,\n",
    "    MiniRocketMultivariate,\n",
    "    MultiRocket,\n",
    "    MultiRocketMultivariate,\n",
    "    Rocket,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b566f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = {\n",
    "            \"num_kernels\": 10000,\n",
    "            \"random_state\": None,\n",
    "            \"n_jobs\": 10,\n",
    "        }\n",
    "\n",
    "result_DF = pd.DataFrame(columns = ['Confusion_Matrix(tn, fp, fn, tp)', 'Accur', 'TSS', 'HSS', 'GSS', 'TPR', 'TNR', 'CBNPr', 'XMPr', 'FAR', 'POFD', 'f1XM', 'f1CBN', 'Experiments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c2803be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p5, class_weights:{CBN:1, XM:5}\n",
      "\tTraining time: 5234.51 s\n",
      "\tPredicting time: 704.83 s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result_DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, multivar_rocket_)\n\u001b[1;32m     19\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEp5_cw1:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(cw)]\n\u001b[0;32m---> 20\u001b[0m result_DF \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mresult_DF\u001b[49m,result])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEvaluation time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt2, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# the time would be round to 3 decimal in seconds\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_DF' is not defined"
     ]
    }
   ],
   "source": [
    "cw=5\n",
    "\n",
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "print('Testing p5, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp5, y_train_TEp5)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp5)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp5_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02887db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p4, class_weights:{CBN:1, XM:5}\n",
      "\tTraining time: 5788.42 s\n",
      "\tPredicting time: 469.45 s\n",
      "\tEvaluation time: 466.41 s\n"
     ]
    }
   ],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p4, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp4, y_train_TEp4)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp4 = multivar_rocket_.predict(X_test_TEp4)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp4, y_test_TEp4, y_pred_TEp4, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp4_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd397443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p3, class_weights:{CBN:1, XM:5}\n",
      "\tTraining time: 5737.4 s\n",
      "\tPredicting time: 389.61 s\n",
      "\tEvaluation time: 388.91 s\n"
     ]
    }
   ],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p3, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp3, y_train_TEp3)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp3 = multivar_rocket_.predict(X_test_TEp3)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp3, y_test_TEp3, y_pred_TEp3, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp3_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da44face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p2, class_weights:{CBN:1, XM:5}\n",
      "\tTraining time: 4954.15 s\n",
      "\tPredicting time: 800.56 s\n",
      "\tEvaluation time: 825.55 s\n"
     ]
    }
   ],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p2, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp2, y_train_TEp2)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp2 = multivar_rocket_.predict(X_test_TEp2)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp2, y_test_TEp2, y_pred_TEp2, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp2_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19fb5a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p1, class_weights:{CBN:1, XM:5}\n",
      "\tTraining time: 5304.27 s\n",
      "\tPredicting time: 674.79 s\n",
      "\tEvaluation time: 699.52 s\n"
     ]
    }
   ],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': [5:10]}),\n",
    "            )\n",
    "\n",
    "print('Testing p1, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp1, y_train_TEp1)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp1 = multivar_rocket_.predict(X_test_TEp1)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp1, y_test_TEp1, y_pred_TEp1, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp1_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "168936f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confusion_Matrix(tn, fp, fn, tp)</th>\n",
       "      <th>Accur</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>GSS</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>CBNPr</th>\n",
       "      <th>XMPr</th>\n",
       "      <th>FAR</th>\n",
       "      <th>POFD</th>\n",
       "      <th>f1XM</th>\n",
       "      <th>f1CBN</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[73840, 462, 829, 161]</td>\n",
       "      <td>0.982853</td>\n",
       "      <td>0.156408</td>\n",
       "      <td>0.191415</td>\n",
       "      <td>0.105837</td>\n",
       "      <td>0.162626</td>\n",
       "      <td>0.993782</td>\n",
       "      <td>0.988898</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.199628</td>\n",
       "      <td>0.991334</td>\n",
       "      <td>TEp5_cw1:5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[49664, 390, 954, 211]</td>\n",
       "      <td>0.973760</td>\n",
       "      <td>0.173324</td>\n",
       "      <td>0.226991</td>\n",
       "      <td>0.128026</td>\n",
       "      <td>0.181116</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>0.351082</td>\n",
       "      <td>0.648918</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.238958</td>\n",
       "      <td>0.986650</td>\n",
       "      <td>TEp4_cw1:5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[40615, 443, 1109, 315]</td>\n",
       "      <td>0.963467</td>\n",
       "      <td>0.210418</td>\n",
       "      <td>0.271766</td>\n",
       "      <td>0.157251</td>\n",
       "      <td>0.221208</td>\n",
       "      <td>0.989210</td>\n",
       "      <td>0.973421</td>\n",
       "      <td>0.415567</td>\n",
       "      <td>0.584433</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.288726</td>\n",
       "      <td>0.981252</td>\n",
       "      <td>TEp3_cw1:5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[85684, 599, 1171, 230]</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.157226</td>\n",
       "      <td>0.196736</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.164168</td>\n",
       "      <td>0.993058</td>\n",
       "      <td>0.986518</td>\n",
       "      <td>0.277443</td>\n",
       "      <td>0.722557</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>TEp2_cw1:5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[71849, 389, 1121, 134]</td>\n",
       "      <td>0.979454</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.142113</td>\n",
       "      <td>0.076492</td>\n",
       "      <td>0.106773</td>\n",
       "      <td>0.994615</td>\n",
       "      <td>0.984638</td>\n",
       "      <td>0.256214</td>\n",
       "      <td>0.743786</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.150731</td>\n",
       "      <td>0.989601</td>\n",
       "      <td>TEp1_cw1:5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Confusion_Matrix(tn, fp, fn, tp)     Accur       TSS       HSS       GSS  \\\n",
       "0           [73840, 462, 829, 161]  0.982853  0.156408  0.191415  0.105837   \n",
       "0           [49664, 390, 954, 211]  0.973760  0.173324  0.226991  0.128026   \n",
       "0          [40615, 443, 1109, 315]  0.963467  0.210418  0.271766  0.157251   \n",
       "0          [85684, 599, 1171, 230]  0.979814  0.157226  0.196736  0.109100   \n",
       "0          [71849, 389, 1121, 134]  0.979454  0.101388  0.142113  0.076492   \n",
       "\n",
       "        TPR       TNR     CBNPr      XMPr       FAR      POFD      f1XM  \\\n",
       "0  0.162626  0.993782  0.988898  0.258427  0.741573  0.006218  0.199628   \n",
       "0  0.181116  0.992208  0.981153  0.351082  0.648918  0.007792  0.238958   \n",
       "0  0.221208  0.989210  0.973421  0.415567  0.584433  0.010790  0.288726   \n",
       "0  0.164168  0.993058  0.986518  0.277443  0.722557  0.006942  0.206278   \n",
       "0  0.106773  0.994615  0.984638  0.256214  0.743786  0.005385  0.150731   \n",
       "\n",
       "      f1CBN Experiments  \n",
       "0  0.991334  TEp5_cw1:5  \n",
       "0  0.986650  TEp4_cw1:5  \n",
       "0  0.981252  TEp3_cw1:5  \n",
       "0  0.989777  TEp2_cw1:5  \n",
       "0  0.989601  TEp1_cw1:5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a61b0",
   "metadata": {},
   "source": [
    "# Customized scoring and cv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36996271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rocket(X_train,y_train,X_test,y_test,len_cv,test_label='p5'):\n",
    "    groups = np.array([0] * len_cv[0] + [1] * len_cv[1] + [2] * len_cv[2] + [3] * len_cv[3])\n",
    "    cv = GroupKFold(n_splits=4)\n",
    "    train_index_1, train_index_2, train_index_3, train_index_4 = cv.split(X_train,y_train, groups)\n",
    "    custom_cv = [train_index_1, train_index_2, train_index_3, train_index_4]\n",
    "    \n",
    "    common_params = {\n",
    "            \"num_kernels\": 1000,\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": 10,\n",
    "        }\n",
    "\n",
    "    result_DF = pd.DataFrame(columns = ['Confusion_Matrix(tn, fp, fn, tp)', 'Accur', 'TSS', 'HSS', 'GSS', 'TPR', 'TNR', 'CBNPr', 'XMPr', 'FAR', 'POFD', 'f1XM', 'f1CBN', 'Experiments'])\n",
    "\n",
    "    cws=[5,6,7,8,9,10]\n",
    "    for cw in cws:\n",
    "        multivar_rocket_ = make_pipeline(\n",
    "                        Rocket(**common_params),\n",
    "                        StandardScaler(with_mean=False),\n",
    "                        RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}, cv=custom_cv, scoring=make_scorer(measurements.geometric_mean, greater_is_better=True))\n",
    "                    )\n",
    "\n",
    "        print('Testing '+test_label+', class_weights: {CBN:1, XM:'+str(cw)+'}')\n",
    "        t0=time.time()\n",
    "        multivar_rocket_.fit(X_train, y_train)\n",
    "#         joblib.dump(multivar_rocket_, './models/Rocket/TE'+test_label+'_cw'+str(cw)+'.sav')\n",
    "        print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "        t1=time.time()\n",
    "        y_pred = multivar_rocket_.predict(X_test)\n",
    "        print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "        t2=time.time()\n",
    "        result = evaluation(X_test, y_test, y_pred, multivar_rocket_)\n",
    "        result['Experiments'] = ['TE'+test_label+'_cw'+str(cw)]\n",
    "        result_DF = pd.concat([result_DF,result])\n",
    "        print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    #     results = ridge.cv_results_\n",
    "    #     allFoldResults_DF = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    result_DF = result_DF.reset_index(drop=True)\n",
    "    return result_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c2ad0f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p5, class_weights: {CBN:1, XM:5}\n",
      "\tTraining time: 8497.37 s\n",
      "\tPredicting time: 715.8 s\n",
      "\tEvaluation time: 677.62 s\n",
      "Testing p5, class_weights: {CBN:1, XM:6}\n",
      "\tTraining time: 8812.5 s\n",
      "\tPredicting time: 677.4 s\n",
      "\tEvaluation time: 712.25 s\n",
      "Testing p5, class_weights: {CBN:1, XM:7}\n",
      "\tTraining time: 8778.13 s\n",
      "\tPredicting time: 678.1 s\n",
      "\tEvaluation time: 682.61 s\n",
      "Testing p5, class_weights: {CBN:1, XM:8}\n",
      "\tTraining time: 8826.94 s\n",
      "\tPredicting time: 687.16 s\n",
      "\tEvaluation time: 679.2 s\n",
      "Testing p5, class_weights: {CBN:1, XM:9}\n",
      "\tTraining time: 8830.43 s\n",
      "\tPredicting time: 682.87 s\n",
      "\tEvaluation time: 679.24 s\n",
      "Testing p5, class_weights: {CBN:1, XM:10}\n",
      "\tTraining time: 8921.35 s\n",
      "\tPredicting time: 686.05 s\n",
      "\tEvaluation time: 720.8 s\n"
     ]
    }
   ],
   "source": [
    "result_TEp5 = train_rocket(X_train_TEp5,y_train_TEp5,X_test_TEp5,y_test_TEp5,[len(partition1),len(partition2),len(partition3),len(partition4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bca7bb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSS      0.279472\n",
       "HSS      0.249918\n",
       "CBNPr    0.983659\n",
       "XMPr     0.257230\n",
       "FAR      0.742770\n",
       "TPR      0.300572\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_TEp4[['TSS','HSS','CBNPr','XMPr','FAR','TPR']].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ae0fead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_TEp5.to_csv('./results/Rocket/TEp5_cw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa2ba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p4, class_weights: {CBN:1, XM:5}\n",
      "\tTraining time: 2389.21 s\n",
      "\tPredicting time: 352.22 s\n",
      "\tEvaluation time: 377.02 s\n",
      "Testing p4, class_weights: {CBN:1, XM:6}\n",
      "\tTraining time: 2450.7 s\n",
      "\tPredicting time: 348.59 s\n",
      "\tEvaluation time: 349.65 s\n",
      "Testing p4, class_weights: {CBN:1, XM:7}\n",
      "\tTraining time: 2342.25 s\n",
      "\tPredicting time: 370.06 s\n",
      "\tEvaluation time: 344.15 s\n",
      "Testing p4, class_weights: {CBN:1, XM:8}\n",
      "\tTraining time: 2338.23 s\n",
      "\tPredicting time: 377.76 s\n",
      "\tEvaluation time: 350.06 s\n",
      "Testing p4, class_weights: {CBN:1, XM:9}\n",
      "\tTraining time: 2346.33 s\n",
      "\tPredicting time: 349.41 s\n",
      "\tEvaluation time: 377.75 s\n",
      "Testing p4, class_weights: {CBN:1, XM:10}\n",
      "\tTraining time: 2335.74 s\n",
      "\tPredicting time: 348.91 s\n",
      "\tEvaluation time: 349.86 s\n"
     ]
    }
   ],
   "source": [
    "result_TEp4 = train_rocket(X_train_TEp4,y_train_TEp4,X_test_TEp4,y_test_TEp4,[len(partition1),len(partition2),len(partition3),len(partition5)],test_label='p4')\n",
    "result_TEp4.to_csv('./results/Rocket/TEp4_cw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bb80530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p3, class_weights: {CBN:1, XM:5}\n",
      "\tTraining time: 2438.71 s\n",
      "\tPredicting time: 291.33 s\n",
      "\tEvaluation time: 289.75 s\n",
      "Testing p3, class_weights: {CBN:1, XM:6}\n",
      "\tTraining time: 2422.9 s\n",
      "\tPredicting time: 321.6 s\n",
      "\tEvaluation time: 285.88 s\n",
      "Testing p3, class_weights: {CBN:1, XM:7}\n",
      "\tTraining time: 2390.5 s\n",
      "\tPredicting time: 286.32 s\n",
      "\tEvaluation time: 285.08 s\n",
      "Testing p3, class_weights: {CBN:1, XM:8}\n",
      "\tTraining time: 2427.8 s\n",
      "\tPredicting time: 287.79 s\n",
      "\tEvaluation time: 285.31 s\n",
      "Testing p3, class_weights: {CBN:1, XM:9}\n",
      "\tTraining time: 2398.0 s\n",
      "\tPredicting time: 286.1 s\n",
      "\tEvaluation time: 288.84 s\n",
      "Testing p3, class_weights: {CBN:1, XM:10}\n",
      "\tTraining time: 2433.95 s\n",
      "\tPredicting time: 285.64 s\n",
      "\tEvaluation time: 286.5 s\n"
     ]
    }
   ],
   "source": [
    "result_TEp3 = train_rocket(X_train_TEp3,y_train_TEp3,X_test_TEp3,y_test_TEp3,[len(partition1),len(partition2),len(partition4),len(partition5)],test_label='p3')\n",
    "result_TEp3.to_csv('./results/Rocket/TEp3_cw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2b487fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p2, class_weights: {CBN:1, XM:5}\n",
      "\tTraining time: 2034.77 s\n",
      "\tPredicting time: 597.1 s\n",
      "\tEvaluation time: 589.38 s\n",
      "Testing p2, class_weights: {CBN:1, XM:6}\n",
      "\tTraining time: 2049.47 s\n",
      "\tPredicting time: 594.68 s\n",
      "\tEvaluation time: 590.88 s\n",
      "Testing p2, class_weights: {CBN:1, XM:7}\n",
      "\tTraining time: 2018.59 s\n",
      "\tPredicting time: 608.44 s\n",
      "\tEvaluation time: 608.11 s\n",
      "Testing p2, class_weights: {CBN:1, XM:8}\n",
      "\tTraining time: 2140.0 s\n",
      "\tPredicting time: 608.57 s\n",
      "\tEvaluation time: 604.64 s\n",
      "Testing p2, class_weights: {CBN:1, XM:9}\n",
      "\tTraining time: 2054.99 s\n",
      "\tPredicting time: 595.73 s\n",
      "\tEvaluation time: 591.77 s\n",
      "Testing p2, class_weights: {CBN:1, XM:10}\n",
      "\tTraining time: 2057.74 s\n",
      "\tPredicting time: 597.38 s\n",
      "\tEvaluation time: 598.53 s\n"
     ]
    }
   ],
   "source": [
    "result_TEp2 = train_rocket(X_train_TEp2,y_train_TEp2,X_test_TEp2,y_test_TEp2,[len(partition1),len(partition3),len(partition4),len(partition5)],test_label='p2')\n",
    "result_TEp2.to_csv('./results/Rocket/TEp2_cw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dea6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p1, class_weights: {CBN:1, XM:5}\n",
      "\tTraining time: 2153.82 s\n",
      "\tPredicting time: 499.6 s\n",
      "\tEvaluation time: 497.84 s\n",
      "Testing p1, class_weights: {CBN:1, XM:6}\n",
      "\tTraining time: 2140.81 s\n",
      "\tPredicting time: 498.11 s\n",
      "\tEvaluation time: 500.06 s\n",
      "Testing p1, class_weights: {CBN:1, XM:7}\n",
      "\tTraining time: 2182.22 s\n",
      "\tPredicting time: 497.47 s\n",
      "\tEvaluation time: 498.38 s\n",
      "Testing p1, class_weights: {CBN:1, XM:8}\n",
      "\tTraining time: 2168.38 s\n",
      "\tPredicting time: 497.3 s\n",
      "\tEvaluation time: 507.16 s\n",
      "Testing p1, class_weights: {CBN:1, XM:9}\n",
      "\tTraining time: 2134.12 s\n",
      "\tPredicting time: 496.78 s\n",
      "\tEvaluation time: 548.48 s\n",
      "Testing p1, class_weights: {CBN:1, XM:10}\n",
      "\tTraining time: 2134.77 s\n",
      "\tPredicting time: 495.44 s\n",
      "\tEvaluation time: 495.37 s\n"
     ]
    }
   ],
   "source": [
    "result_TEp1 = train_rocket(X_train_TEp1,y_train_TEp1,X_test_TEp1,y_test_TEp1,[len(partition2),len(partition3),len(partition4),len(partition5)],test_label='p1')\n",
    "result_TEp1.to_csv('./results/Rocket/TEp1_cw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bede0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all = pd.concat([result_TEp1,result_TEp2,result_TEp3,result_TEp4,result_TEp5])\n",
    "result_all = result_all.reset_index(drop=True)\n",
    "result_all.to_csv('./results/Rocket/TE_cwALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a58117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33a28bb4",
   "metadata": {},
   "source": [
    "# cw10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d46128b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p5, class_weights:{CBN:1, XM:10}\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 152. GiB for an array with shape (254878, 79968) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting p5, class_weights:\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mCBN:1, XM:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(cw)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m t0\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmultivar_rocket_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_TEp5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_TEp5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTraining time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# the time would be round to 3 decimal in seconds\u001b[39;00m\n\u001b[1;32m     13\u001b[0m t1\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/classification/base.py:240\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# pass coerced and checked data to inner _fit\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_time_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)) \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# this should happen last: fitted state is set to True\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/classification/compose/_pipeline.py:525\u001b[0m, in \u001b[0;36mSklearnClassifierPipeline._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit time series classifier to training data.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    core logic\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03m    creates fitted model (attributes ending in \"_\")\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformers_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m     Xt_sklearn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_X_to_sklearn(Xt)\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier_\u001b[38;5;241m.\u001b[39mfit(Xt_sklearn, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/transformations/base.py:681\u001b[0m, in \u001b[0;36mBaseTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit to data, then transform it.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03mFits the transformer to X and y and returns a transformed version of X.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03m        Example: i-th instance of the output is the i-th window running over `X`\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;66;03m# Non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# method is possible for a given algorithm.\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/transformations/base.py:498\u001b[0m, in \u001b[0;36mBaseTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vectorization_needed:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of fit\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m=\u001b[39mX_inner, y\u001b[38;5;241m=\u001b[39my_inner)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/transformations/compose/_pipeline.py:285\u001b[0m, in \u001b[0;36mTransformerPipeline._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    283\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, transformer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_:\n\u001b[0;32m--> 285\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/transformations/base.py:681\u001b[0m, in \u001b[0;36mBaseTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit to data, then transform it.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03mFits the transformer to X and y and returns a transformed version of X.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03m        Example: i-th instance of the output is the i-th window running over `X`\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;66;03m# Non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# method is possible for a given algorithm.\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/transformations/base.py:498\u001b[0m, in \u001b[0;36mBaseTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vectorization_needed:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of fit\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m=\u001b[39mX_inner, y\u001b[38;5;241m=\u001b[39my_inner)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/transformations/series/adapt.py:208\u001b[0m, in \u001b[0;36mTabularToSeriesAdaptor._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    205\u001b[0m y_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_y_args(y, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_fit:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43my_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py:946\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(X)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 946\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m=\u001b[39m \u001b[43m_incremental_mean_and_var\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples_seen_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# missing values)\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mptp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/extmath.py:1053\u001b[0m, in \u001b[0;36m_incremental_mean_and_var\u001b[0;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1052\u001b[0m     T \u001b[38;5;241m=\u001b[39m new_sum \u001b[38;5;241m/\u001b[39m new_sample_count\n\u001b[0;32m-> 1053\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;66;03m# equivalent to np.nansum((X-T)**2 * sample_weight, axis=0)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;66;03m# safer because np.float64(X*W) != np.float64(X)*np.float64(W)\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m         correction \u001b[38;5;241m=\u001b[39m _safe_accumulator_op(\n\u001b[1;32m   1058\u001b[0m             np\u001b[38;5;241m.\u001b[39mmatmul, sample_weight, np\u001b[38;5;241m.\u001b[39mwhere(X_nan_mask, \u001b[38;5;241m0\u001b[39m, temp)\n\u001b[1;32m   1059\u001b[0m         )\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 152. GiB for an array with shape (254878, 79968) and data type float64"
     ]
    }
   ],
   "source": [
    "cw=10\n",
    "\n",
    "multivar_rocket_ = make_pipeline(\n",
    "                MultiRocketMultivariate(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "print('Testing p5, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp5, y_train_TEp5)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp5)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp5_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                MultiRocketMultivariate(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p4, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp4, y_train_TEp4)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp4 = multivar_rocket_.predict(X_test_TEp4)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp4, y_test_TEp4, y_pred_TEp4, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp4_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ee234",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                MultiRocketMultivariate(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p3, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp3, y_train_TEp3)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp3 = multivar_rocket_.predict(X_test_TEp3)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp3, y_test_TEp3, y_pred_TEp3, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp3_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                MultiRocketMultivariate(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p2, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp2, y_train_TEp2)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp2 = multivar_rocket_.predict(X_test_TEp2)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp2, y_test_TEp2, y_pred_TEp2, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp2_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1306e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                MultiRocketMultivariate(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p1, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp1, y_train_TEp1)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp1 = multivar_rocket_.predict(X_test_TEp1)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp1, y_test_TEp1, y_pred_TEp1, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp1_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c14fad",
   "metadata": {},
   "source": [
    "# cw20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw=20\n",
    "\n",
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "print('Testing p5, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp5, y_train_TEp5)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp5)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp5_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd62238",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p4, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp4, y_train_TEp4)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp4 = multivar_rocket_.predict(X_test_TEp4)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp4, y_test_TEp4, y_pred_TEp4, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp4_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p3, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp3, y_train_TEp3)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp3 = multivar_rocket_.predict(X_test_TEp3)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp3, y_test_TEp3, y_pred_TEp3, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp3_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p2, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp2, y_train_TEp2)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp2 = multivar_rocket_.predict(X_test_TEp2)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp2, y_test_TEp2, y_pred_TEp2, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp2_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_rocket_ = make_pipeline(\n",
    "                Rocket(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "\n",
    "print('Testing p1, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "t0=time.time()\n",
    "multivar_rocket_.fit(X_train_TEp1, y_train_TEp1)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp1 = multivar_rocket_.predict(X_test_TEp1)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp1, y_test_TEp1, y_pred_TEp1, multivar_rocket_)\n",
    "result['Experiments'] = ['TEp1_cw1:'+str(cw)]\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4ca29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a3233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7599d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p5, class_weights:{CBN:1, XM:5}\n"
     ]
    }
   ],
   "source": [
    "common_params = {\n",
    "            \"num_kernels\": 10000,\n",
    "            \"random_state\": None,\n",
    "            \"max_dilations_per_kernel\": 32,\n",
    "            \"n_jobs\": 10,\n",
    "        }\n",
    "\n",
    "results_DF = pd.DataFrame(columns = ['Confusion_Matrix(tn, fp, fn, tp)', 'Accur', 'TSS', 'HSS', 'GSS', 'TPR', 'TNR', 'CBNPr', 'XMPr', 'FAR', 'POFD', 'f1XM', 'f1CBN', 'Experiments'])\n",
    "cw_list = [5,6,7,8,9,10,20,30]\n",
    "\n",
    "for cw in cw_list:\n",
    "    multivar_rocket_ = make_pipeline(\n",
    "                MultiRocketMultivariate(**common_params),\n",
    "                StandardScaler(with_mean=False),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), class_weight={'CBN': 1, 'XM': cw}),\n",
    "            )\n",
    "    print('Testing p5, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "    t0=time.time()\n",
    "    multivar_rocket_.fit(X_train_TEp5, y_train_TEp5)\n",
    "    print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "    \n",
    "    t1=time.time()\n",
    "    y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp5)\n",
    "    print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    t2=time.time()\n",
    "    result = evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, multivar_rocket_)\n",
    "    result['Experiments'] = ['TEp5_cw1:'+str(cw)]\n",
    "    result_DF = pd.concat([result_DF,result])\n",
    "    print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    \n",
    "    print('Testing p4, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "    t0=time.time()\n",
    "    multivar_rocket_.fit(X_train_TEp4, y_train_TEp4)\n",
    "    print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "    \n",
    "    t1=time.time()\n",
    "    y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp4)\n",
    "    print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    t2=time.time()\n",
    "    result = evaluation(X_test_TEp4, y_test_TEp4, y_pred_TEp4, multivar_rocket_)\n",
    "    result['Experiments'] = ['TEp4_cw1:'+str(cw)]\n",
    "    result_DF = pd.concat([result_DF,result])\n",
    "    print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    \n",
    "    print('Testing p3, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "    t0=time.time()\n",
    "    multivar_rocket_.fit(X_train_TEp3, y_train_TEp3)\n",
    "    print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "    \n",
    "    t1=time.time()\n",
    "    y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp3)\n",
    "    print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    t2=time.time()\n",
    "    result = evaluation(X_test_TEp3, y_test_TEp3, y_pred_TEp3, multivar_rocket_)\n",
    "    result['Experiments'] = ['TEp3_cw1:'+str(cw)]\n",
    "    result_DF = pd.concat([result_DF,result])\n",
    "    print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    \n",
    "    print('Testing p2, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "    t0=time.time()\n",
    "    multivar_rocket_.fit(X_train_TEp2, y_train_TEp2)\n",
    "    print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "    \n",
    "    t1=time.time()\n",
    "    y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp2)\n",
    "    print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    t2=time.time()\n",
    "    result = evaluation(X_test_TEp2, y_test_TEp2, y_pred_TEp2, multivar_rocket_)\n",
    "    result['Experiments'] = ['TEp2_cw1:'+str(cw)]\n",
    "    result_DF = pd.concat([result_DF,result])\n",
    "    print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    \n",
    "    print('Testing p1, class_weights:{CBN:1, XM:'+str(cw)+'}')\n",
    "    t0=time.time()\n",
    "    multivar_rocket_.fit(X_train_TEp1, y_train_TEp1)\n",
    "    print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "    \n",
    "    t1=time.time()\n",
    "    y_pred_TEp5 = multivar_rocket_.predict(X_test_TEp1)\n",
    "    print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "    t2=time.time()\n",
    "    result = evaluation(X_test_TEp1, y_test_TEp1, y_pred_TEp1, multivar_rocket_)\n",
    "    result['Experiments'] = ['TEp1_cw1:'+str(cw)]\n",
    "    result_DF = pd.concat([result_DF,result])\n",
    "    print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ba0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb10759",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_TEp5 = evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, rocket_TEp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "debad564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confusion_Matrix(tn, fp, fn, tp)</th>\n",
       "      <th>Accur</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>GSS</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>CBNPr</th>\n",
       "      <th>XMPr</th>\n",
       "      <th>FAR</th>\n",
       "      <th>POFD</th>\n",
       "      <th>f1XM</th>\n",
       "      <th>f1CBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[74300, 2, 988, 2]</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.993382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Confusion_Matrix(tn, fp, fn, tp)     Accur       TSS       HSS       GSS  \\\n",
       "0               [74300, 2, 988, 2]  0.986851  0.001993  0.003919  0.001963   \n",
       "\n",
       "       TPR       TNR     CBNPr  XMPr  FAR      POFD      f1XM     f1CBN  \n",
       "0  0.00202  0.999973  0.986877   0.5  0.5  0.000027  0.004024  0.993382  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_TEp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4142e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_TEp5 = evaluation(X_test_transform_TEp5, y_test_TEp5, y_pred_TEp5, RC_TEp5)\n",
    "result_TEp4 = evaluation(X_test_TEp4, y_test_TEp4, y_pred_TEp4, rocket_TEp4)\n",
    "result_TEp3 = evaluation(X_test_TEp3, y_test_TEp3, y_pred_TEp3, rocket_TEp3)\n",
    "result_TEp2 = evaluation(X_test_TEp2, y_test_TEp2, y_pred_TEp2, rocket_TEp2)\n",
    "result_TEp1 = evaluation(X_test_TEp1, y_test_TEp1, y_pred_TEp1, rocket_TEp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7088e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confusion_Matrix(tn, fp, fn, tp)</th>\n",
       "      <th>Accur</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>GSS</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>CBNPr</th>\n",
       "      <th>XMPr</th>\n",
       "      <th>FAR</th>\n",
       "      <th>POFD</th>\n",
       "      <th>f1XM</th>\n",
       "      <th>f1CBN</th>\n",
       "      <th>Experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[74300, 2, 988, 2]</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.993382</td>\n",
       "      <td>TEp5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[50050, 4, 1159, 6]</td>\n",
       "      <td>0.977294</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.977367</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.010213</td>\n",
       "      <td>0.988515</td>\n",
       "      <td>TEp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[41057, 1, 1422, 2]</td>\n",
       "      <td>0.966503</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.966525</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.982966</td>\n",
       "      <td>TEp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[86282, 1, 1400, 1]</td>\n",
       "      <td>0.984022</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.984033</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>TEp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[72236, 2, 1251, 4]</td>\n",
       "      <td>0.982951</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.982977</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.991402</td>\n",
       "      <td>TEp1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Confusion_Matrix(tn, fp, fn, tp)     Accur       TSS       HSS       GSS  \\\n",
       "0               [74300, 2, 988, 2]  0.986851  0.001993  0.003919  0.001963   \n",
       "1              [50050, 4, 1159, 6]  0.977294  0.005070  0.009829  0.004939   \n",
       "2              [41057, 1, 1422, 2]  0.966503  0.001380  0.002663  0.001333   \n",
       "3              [86282, 1, 1400, 1]  0.984022  0.000702  0.001380  0.000690   \n",
       "4              [72236, 2, 1251, 4]  0.982951  0.003160  0.006183  0.003101   \n",
       "\n",
       "        TPR       TNR     CBNPr      XMPr       FAR      POFD      f1XM  \\\n",
       "0  0.002020  0.999973  0.986877  0.500000  0.500000  0.000027  0.004024   \n",
       "1  0.005150  0.999920  0.977367  0.600000  0.400000  0.000080  0.010213   \n",
       "2  0.001404  0.999976  0.966525  0.666667  0.333333  0.000024  0.002803   \n",
       "3  0.000714  0.999988  0.984033  0.500000  0.500000  0.000012  0.001426   \n",
       "4  0.003187  0.999972  0.982977  0.666667  0.333333  0.000028  0.006344   \n",
       "\n",
       "      f1CBN Experiment  \n",
       "0  0.993382       TEp5  \n",
       "1  0.988515       TEp4  \n",
       "2  0.982966       TEp3  \n",
       "3  0.991947       TEp2  \n",
       "4  0.991402       TEp1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([result_TEp5,result_TEp4,result_TEp3,result_TEp2,result_TEp1])\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "result_df['Experiment'] = ['TEp5','TEp4','TEp3','TEp2','TEp1']\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "882bc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./results/Rocket/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f62c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "457799a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data seen by BOSSEnsemble instance has missing values and multivariate series, but this BOSSEnsemble instance cannot handle missing values or multivariate series. Calls with missing values or multivariate series may result in error or unreliable results.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_train_TEp5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((partition1_labels, partition2_labels, partition3_labels, partition4_labels))\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m BOSSEnsemble()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_TEp5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_TEp5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(partition4)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/classification/base.py:212\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X_metadata \u001b[38;5;241m=\u001b[39m X_metadata\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Check this classifier can handle characteristics\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_capabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# remember class labels\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/base/_base_panel.py:252\u001b[0m, in \u001b[0;36mBasePanelMixin._check_capabilities\u001b[0;34m(self, X_metadata)\u001b[0m\n\u001b[1;32m    250\u001b[0m     warn(msg, obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data seen by BOSSEnsemble instance has missing values and multivariate series, but this BOSSEnsemble instance cannot handle missing values or multivariate series. Calls with missing values or multivariate series may result in error or unreliable results."
     ]
    }
   ],
   "source": [
    "# X_train_TEp5 = np.concatenate((partition1, partition2, partition3, partition4))\n",
    "# y_train_TEp5 = np.concatenate((partition1_labels, partition2_labels, partition3_labels, partition4_labels))\n",
    "\n",
    "# clf = BOSSEnsemble()\n",
    "# clf.fit(X_train_TEp5, y_train_TEp5)\n",
    "# y_pred = clf.predict(partition4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ef0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
