{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ed42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "from sktime.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import Measurements as measurements\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sktime.classification.interval_based import DrCIF\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import Feature_rank_lib as lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2467cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method extract the necessary features from the destination folder\n",
    "def data_reader(loadPath, partitions, flare_label):\n",
    "    cols = ['USFLUX','TOTUSJZ','TOTUSJH','ABSNJZH','SAVNCPP','TOTPOT','TOTBSQ','TOTFZ','MEANPOT','EPSZ','MEANSHR','SHRGT45','MEANGAM','MEANGBT','MEANGBZ','MEANGBH','MEANJZH','TOTFY','MEANJZD','MEANALP','TOTFX','EPSY','EPSX','R_VALUE']\n",
    "    # Read files from the define path\n",
    "    all_files = glob.glob(str(loadPath) + partitions + \"/\" + flare_label + \"/*.csv\")\n",
    "\n",
    "    li = []\n",
    "    for filename in all_files:\n",
    "        # Read the file and extract necessary features\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, sep='\\t')\n",
    "        df.interpolate(method='linear', axis=0, limit_direction='both', inplace = True)\n",
    "#         # Extract label info\n",
    "#         INFO = filename.split('/')[-1]\n",
    "        # Define Label value based on the file name\n",
    "    \n",
    "        if flare_label == 'NF':\n",
    "            LABEL = 'CBN'\n",
    "        else:\n",
    "            LABEL = 'XM'\n",
    "            \n",
    "        col_list = []\n",
    "        for col in cols:\n",
    "            if not df[col].isnull().values.all(axis=0):\n",
    "                col_list.append(df[col])\n",
    "        if len(col_list) == 24:\n",
    "            li.append(col_list + [LABEL])\n",
    "\n",
    "    # Create and return the dataframe build on the extracted features\n",
    "    partition_frame = pd.DataFrame(li, columns= cols + ['LABEL'])\n",
    "    return partition_frame\n",
    "\n",
    "def evaluation(x_test, y_test, y_pred, clf):\n",
    "    scores = confusion_matrix(y_test, y_pred, labels=['CBN', 'XM']).ravel()\n",
    "    tn, fp, fn, tp = scores\n",
    "\n",
    "    results_DF = pd.DataFrame(columns = ['Confusion_Matrix(tn, fp, fn, tp)', 'Accur', 'TSS', 'HSS', 'GSS', 'TPR', 'TNR', 'CBNPr', 'XMPr', 'FAR', 'POFD', 'f1XM', 'f1CBN'], index = [0])\n",
    "\n",
    "    #Confusion Matrix\n",
    "    results_DF['Confusion_Matrix(tn, fp, fn, tp)'] = [scores]\n",
    "    \n",
    "    #Accuracy\n",
    "    scoreTest = clf.score(x_test, y_test)\n",
    "    #print(\"Train Accuracy: \" + str(round(scoreTrain, 4)))\n",
    "    #print(\"Test Accuracy: \" + str(round(scoreTest, 4)))\n",
    "    results_DF['Accur'] = scoreTest\n",
    "\n",
    "    # TSS\n",
    "    tss = measurements.TSS(scores)\n",
    "    results_DF['TSS'] = tss\n",
    "\n",
    "    # HSS2 Definition 2\n",
    "    hss2 = measurements.HSS2(scores)\n",
    "    results_DF['HSS'] = hss2\n",
    "\n",
    "    # GSS\n",
    "    gss = measurements.GSS(scores)\n",
    "    results_DF['GSS'] = gss\n",
    "\n",
    "    # TPR\n",
    "    tpr = measurements.TPR(scores)\n",
    "    results_DF['TPR'] = tpr\n",
    "    \n",
    "    # TNR\n",
    "    tnr = measurements.TNR(scores)\n",
    "    results_DF['TNR'] = tnr\n",
    "\n",
    "    # Precision Negative\n",
    "    negPrecision = measurements.precisionNeg(scores)\n",
    "    results_DF['CBNPr'] = negPrecision\n",
    "    \n",
    "    # Precision Positive\n",
    "    posPrecision = measurements.precisionPos(scores)\n",
    "    results_DF['XMPr'] = posPrecision\n",
    "\n",
    "    # FAR\n",
    "    far = measurements.FAR(scores)\n",
    "    results_DF['FAR'] = far\n",
    "\n",
    "    # POFD\n",
    "    pofd = measurements.POFD(scores)\n",
    "    results_DF['POFD'] = pofd\n",
    "\n",
    "    # F1(XM)\n",
    "    f1XM = measurements.F1Pos(scores)\n",
    "    results_DF['f1XM'] = f1XM\n",
    "\n",
    "    # F1(CBN)\n",
    "    f1CBN = measurements.F1Neg(scores)\n",
    "    results_DF['f1CBN'] = f1CBN\n",
    "\n",
    "    # Return the result measurement dataframe\n",
    "    return results_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8d5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/data/SHARPS/BERKAY/v0.7/new-data-folds/instances_O12L0P24/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72feeaed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partition1_FL = data_reader(datapath,'partition1','FL')\n",
    "partition1_NF = data_reader(datapath,'partition1','NF')\n",
    "\n",
    "partition2_FL = data_reader(datapath,'partition2','FL')\n",
    "partition2_NF = data_reader(datapath,'partition2','NF')\n",
    "\n",
    "partition3_FL = data_reader(datapath,'partition3','FL')\n",
    "partition3_NF = data_reader(datapath,'partition3','NF')\n",
    "\n",
    "partition4_FL = data_reader(datapath,'partition4','FL')\n",
    "partition4_NF = data_reader(datapath,'partition4','NF')\n",
    "\n",
    "partition5_FL = data_reader(datapath,'partition5','FL')\n",
    "partition5_NF = data_reader(datapath,'partition5','NF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223315c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition1 = pd.concat([partition1_FL, partition1_NF], ignore_index=True)\n",
    "partition2 = pd.concat([partition2_FL, partition2_NF], ignore_index=True)\n",
    "partition3 = pd.concat([partition3_FL, partition3_NF], ignore_index=True)\n",
    "partition4 = pd.concat([partition4_FL, partition4_NF], ignore_index=True)\n",
    "partition5 = pd.concat([partition5_FL, partition5_NF], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f417a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TEp5 = pd.concat([partition1, partition2, partition3, partition4], ignore_index=True)\n",
    "X_train_TEp4 = pd.concat([partition1, partition2, partition3, partition5], ignore_index=True)\n",
    "X_train_TEp3 = pd.concat([partition1, partition2, partition4, partition5], ignore_index=True)\n",
    "X_train_TEp2 = pd.concat([partition1, partition3, partition4, partition5], ignore_index=True)\n",
    "X_train_TEp1 = pd.concat([partition2, partition3, partition4, partition5], ignore_index=True)\n",
    "\n",
    "y_train_TEp5 = X_train_TEp5['LABEL']\n",
    "X_train_TEp5 = X_train_TEp5.loc[:, X_train_TEp5.columns != 'LABEL']\n",
    "y_train_TEp4 = X_train_TEp4['LABEL']\n",
    "X_train_TEp4 = X_train_TEp4.loc[:, X_train_TEp4.columns != 'LABEL']\n",
    "y_train_TEp3 = X_train_TEp3['LABEL']\n",
    "X_train_TEp3 = X_train_TEp3.loc[:, X_train_TEp3.columns != 'LABEL']\n",
    "y_train_TEp2 = X_train_TEp2['LABEL']\n",
    "X_train_TEp2 = X_train_TEp2.loc[:, X_train_TEp2.columns != 'LABEL']\n",
    "y_train_TEp1 = X_train_TEp1['LABEL']\n",
    "X_train_TEp1 = X_train_TEp1.loc[:, X_train_TEp1.columns != 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a05eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_TEp5 = partition5.loc[:, partition5.columns != 'LABEL']\n",
    "y_test_TEp5 = partition5['LABEL']\n",
    "X_test_TEp4 = partition4.loc[:, partition4.columns != 'LABEL']\n",
    "y_test_TEp4 = partition4['LABEL']\n",
    "X_test_TEp3 = partition3.loc[:, partition3.columns != 'LABEL']\n",
    "y_test_TEp3 = partition3['LABEL']\n",
    "X_test_TEp2 = partition2.loc[:, partition2.columns != 'LABEL']\n",
    "y_test_TEp2 = partition2['LABEL']\n",
    "X_test_TEp1 = partition1.loc[:, partition1.columns != 'LABEL']\n",
    "y_test_TEp1 = partition1['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1fdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "711bc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_DF = pd.DataFrame(columns = ['Confusion_Matrix(tn, fp, fn, tp)', 'Accur', 'TSS', 'HSS', 'GSS', 'TPR', 'TNR', 'CBNPr', 'XMPr', 'FAR', 'POFD', 'f1XM', 'f1CBN', 'Experiments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b43e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.feature_based import SummaryClassifier\n",
    "from sktime.classification.deep_learning import InceptionTimeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b3aa162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p5\n",
      "\tTraining time: 6434.16 s\n",
      "\tPredicting time: 1714.84 s\n",
      "\tEvaluation time: 1751.3 s\n"
     ]
    }
   ],
   "source": [
    "clf = SummaryClassifier(n_jobs=10)\n",
    "# clf = InceptionTimeClassifier(n_epochs=100,kernel_size=30,metrics=make_scorer(measurements.geometric_mean, greater_is_better=True))\n",
    "\n",
    "print('Testing p5')\n",
    "t0=time.time()\n",
    "clf.fit(X_train_TEp5, y_train_TEp5)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp5 = clf.predict(X_test_TEp5)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp5, y_test_TEp5, y_pred_TEp5, clf)\n",
    "result['Experiments'] = 'TEp5'\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a1b4705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p4\n",
      "\tTraining time: 6999.78 s\n",
      "\tPredicting time: 1169.0 s\n",
      "\tEvaluation time: 1208.92 s\n"
     ]
    }
   ],
   "source": [
    "clf = SummaryClassifier(n_jobs=10)\n",
    "# clf = InceptionTimeClassifier(n_epochs=100,kernel_size=30,metrics=make_scorer(measurements.geometric_mean, greater_is_better=True))\n",
    "\n",
    "print('Testing p4')\n",
    "t0=time.time()\n",
    "clf.fit(X_train_TEp4, y_train_TEp4)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp4 = clf.predict(X_test_TEp4)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp4, y_test_TEp4, y_pred_TEp4, clf)\n",
    "result['Experiments'] = 'TEp4'\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86eb2904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p3\n",
      "\tTraining time: 7181.91 s\n",
      "\tPredicting time: 968.59 s\n",
      "\tEvaluation time: 964.96 s\n"
     ]
    }
   ],
   "source": [
    "clf = SummaryClassifier(n_jobs=10)\n",
    "# clf = InceptionTimeClassifier(n_epochs=100,kernel_size=30,metrics=make_scorer(measurements.geometric_mean, greater_is_better=True))\n",
    "\n",
    "print('Testing p3')\n",
    "t0=time.time()\n",
    "clf.fit(X_train_TEp3, y_train_TEp3)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp3 = clf.predict(X_test_TEp3)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp3, y_test_TEp3, y_pred_TEp3, clf)\n",
    "result['Experiments'] = 'TEp3'\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2d4f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p2\n",
      "\tTraining time: 6041.75 s\n",
      "\tPredicting time: 1994.17 s\n",
      "\tEvaluation time: 1999.39 s\n"
     ]
    }
   ],
   "source": [
    "clf = SummaryClassifier(n_jobs=10)\n",
    "# clf = InceptionTimeClassifier(n_epochs=100,kernel_size=30,metrics=make_scorer(measurements.geometric_mean, greater_is_better=True))\n",
    "\n",
    "print('Testing p2')\n",
    "t0=time.time()\n",
    "clf.fit(X_train_TEp2, y_train_TEp2)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp2 = clf.predict(X_test_TEp2)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp2, y_test_TEp2, y_pred_TEp2, clf)\n",
    "result['Experiments'] = 'TEp2'\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7147b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing p1\n",
      "\tTraining time: 6411.09 s\n",
      "\tPredicting time: 1675.3 s\n",
      "\tEvaluation time: 1672.67 s\n"
     ]
    }
   ],
   "source": [
    "clf = SummaryClassifier(n_jobs=10)\n",
    "# clf = InceptionTimeClassifier(n_epochs=100,kernel_size=30,metrics=make_scorer(measurements.geometric_mean, greater_is_better=True))\n",
    "\n",
    "print('Testing p1')\n",
    "t0=time.time()\n",
    "clf.fit(X_train_TEp1, y_train_TEp1)\n",
    "print(\"\\tTraining time:\", round(time.time()-t0, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t1=time.time()\n",
    "y_pred_TEp1 = clf.predict(X_test_TEp1)\n",
    "print(\"\\tPredicting time:\", round(time.time()-t1, 2), \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "t2=time.time()\n",
    "result = evaluation(X_test_TEp1, y_test_TEp1, y_pred_TEp1, clf)\n",
    "result['Experiments'] = 'TEp1'\n",
    "result_DF = pd.concat([result_DF,result])\n",
    "print(\"\\tEvaluation time:\", round(time.time()-t2, 2), \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acfd1ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confusion_Matrix(tn, fp, fn, tp)</th>\n",
       "      <th>Accur</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>GSS</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>CBNPr</th>\n",
       "      <th>XMPr</th>\n",
       "      <th>FAR</th>\n",
       "      <th>POFD</th>\n",
       "      <th>f1XM</th>\n",
       "      <th>f1CBN</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[74189, 113, 840, 150]</td>\n",
       "      <td>0.987343</td>\n",
       "      <td>0.149994</td>\n",
       "      <td>0.235204</td>\n",
       "      <td>0.133275</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>0.988804</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>0.429658</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.239425</td>\n",
       "      <td>0.993618</td>\n",
       "      <td>TEp5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[49963, 91, 992, 173]</td>\n",
       "      <td>0.978856</td>\n",
       "      <td>0.146680</td>\n",
       "      <td>0.235704</td>\n",
       "      <td>0.133597</td>\n",
       "      <td>0.148498</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.980532</td>\n",
       "      <td>0.655303</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.242127</td>\n",
       "      <td>0.989278</td>\n",
       "      <td>TEp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[40789, 269, 1115, 309]</td>\n",
       "      <td>0.967421</td>\n",
       "      <td>0.210443</td>\n",
       "      <td>0.295047</td>\n",
       "      <td>0.173053</td>\n",
       "      <td>0.216994</td>\n",
       "      <td>0.993448</td>\n",
       "      <td>0.973392</td>\n",
       "      <td>0.534602</td>\n",
       "      <td>0.465398</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.308691</td>\n",
       "      <td>0.983318</td>\n",
       "      <td>TEp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[85863, 420, 925, 476]</td>\n",
       "      <td>0.984661</td>\n",
       "      <td>0.334890</td>\n",
       "      <td>0.407063</td>\n",
       "      <td>0.255542</td>\n",
       "      <td>0.339757</td>\n",
       "      <td>0.995132</td>\n",
       "      <td>0.989342</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.414454</td>\n",
       "      <td>0.992229</td>\n",
       "      <td>TEp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[72144, 94, 1076, 179]</td>\n",
       "      <td>0.984080</td>\n",
       "      <td>0.141328</td>\n",
       "      <td>0.229592</td>\n",
       "      <td>0.129683</td>\n",
       "      <td>0.142629</td>\n",
       "      <td>0.998699</td>\n",
       "      <td>0.985305</td>\n",
       "      <td>0.655678</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.234293</td>\n",
       "      <td>0.991956</td>\n",
       "      <td>TEp1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Confusion_Matrix(tn, fp, fn, tp)     Accur       TSS       HSS       GSS  \\\n",
       "0           [74189, 113, 840, 150]  0.987343  0.149994  0.235204  0.133275   \n",
       "0            [49963, 91, 992, 173]  0.978856  0.146680  0.235704  0.133597   \n",
       "0          [40789, 269, 1115, 309]  0.967421  0.210443  0.295047  0.173053   \n",
       "0           [85863, 420, 925, 476]  0.984661  0.334890  0.407063  0.255542   \n",
       "0           [72144, 94, 1076, 179]  0.984080  0.141328  0.229592  0.129683   \n",
       "\n",
       "        TPR       TNR     CBNPr      XMPr       FAR      POFD      f1XM  \\\n",
       "0  0.151515  0.998479  0.988804  0.570342  0.429658  0.001521  0.239425   \n",
       "0  0.148498  0.998182  0.980532  0.655303  0.344697  0.001818  0.242127   \n",
       "0  0.216994  0.993448  0.973392  0.534602  0.465398  0.006552  0.308691   \n",
       "0  0.339757  0.995132  0.989342  0.531250  0.468750  0.004868  0.414454   \n",
       "0  0.142629  0.998699  0.985305  0.655678  0.344322  0.001301  0.234293   \n",
       "\n",
       "      f1CBN Experiments  \n",
       "0  0.993618        TEp5  \n",
       "0  0.989278        TEp4  \n",
       "0  0.983318        TEp3  \n",
       "0  0.992229        TEp2  \n",
       "0  0.991956        TEp1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec38d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
